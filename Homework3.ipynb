{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce0220",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bfed1",
   "metadata": {},
   "source": [
    "## Exercise 2.2\n",
    "\n",
    "1. Verify the bound of Theorem 2.4 in the three cases of Example 2.2:\n",
    "  \n",
    "  1. Positive rays: $\\mathcal{H}$ consists of all hypothesis in one dimension of the form $h(x) = \\text{sign}(x - a)$. $k = 2$\n",
    "    \n",
    "  2. Positive intervals: $\\mathcal{H}$ consists of all hypotheses in one dimension that are positive within some interval and negative elsewhere. $k = 3$\n",
    "    \n",
    "  3. Convex sets: $\\mathcal{H}$ consists of all hypothesis in two dimensions that are positive inside some convex set and negative elsewhere\n",
    "    \n",
    "  \n",
    "  Note: you can use the break points you found in Exercise 2.1\n",
    "  \n",
    "2. Does there exist a hypothesis set for which $m_\\mathcal{H}(N) = N + 2^{\\lfloor N / 2 \\rfloor}$ (where $\\lfloor N / 2 \\rfloor$ is the largest integer $\\le N / 2$)?\n",
    "  \n",
    "\n",
    "### Solution:\n",
    "\n",
    "1.1 Positive rays. We know that that $m_\\mathcal{H}(N) = N + 1$. So our break point is $k = 2$.\n",
    "\n",
    "So now what we need to write is the following,\n",
    "\n",
    "$$\n",
    "\\sum_{i = 0}^{k - 1} {N \\choose i} = \\sum_{i = 0}^{ 1} {N \\choose i} = {N! \\over 0!N!} + {N! \\over 1! (N-1)!} = 1 + N\n",
    "$$\n",
    "\n",
    "thanks we also know that as $k$ increases then $\\sum_{i=0}^{k-1}{N \\choose i}$ also increases. So the theorem is true for $k \\ge 2$.\n",
    "\n",
    "1.2 Positive intervals. We know that $m_\\mathcal{H}(N) = {1 \\over 2}N^2 + {1 \\over 2}N + 1$. So our break point is $k = 3$.\n",
    "\n",
    "So now we can write the following,\n",
    "\n",
    "$$\n",
    "\\sum_{i = 0}^{k - 1}{N \\choose i} = \\sum_{i = 0}^{2}{N \\choose i} = 1 + N + {N! \\over 2! (N -2)!} = 1 + N + {(N-1)N \\over 2}\n",
    "$$$$\n",
    "\\sum_{i = 0}^{k - 1}{N \\choose i} =  1 + N + {1 \\over 2}N^2 - {1 \\over 2}N = {1 \\over 2}N^2 + {1 \\over 2}N + 1\n",
    "$$\n",
    "\n",
    "So we know that the theorem is true for $k = 3$. Now as we know that $\\sum_{i = 0}^{k - 1}{N \\choose i}$ is non-decreasing so the theorem is true for $k \\ge 3$.\n",
    "\n",
    "1.3 Convex set. We know that $m_\\mathcal{H}(N) = 2^N$. So the theorem is true for vacuous true.\n",
    "\n",
    "2 It exists it is obviously connected to a bi-decision type of model (with binary-trees maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d8115",
   "metadata": {},
   "source": [
    "## Exercise 2.5\n",
    "\n",
    "Suppose we have a simple learning model whose growth function is $m_\\mathcal{H}(N) = N + 1$, hence $d_{\\text{VC}} = 1$ (Haha $k = 2$ for positive rays). Use the VC bound (2.12) to estimate the probability that $E_{\\text{out}}$ will be within 0.1 of $E_{\\text{in}}$ given 100 training samples. [Hint: The estimate will be ridiculous]\n",
    "\n",
    "### Solution ?\n",
    "\n",
    "$$\n",
    "E_{\\text{out}}(g) \\le E_\\text{in}(g) + \\sqrt{{8 \\over N} \\ln {4m_\\mathcal{H}(2N) \\over \\delta}}\n",
    "$$$$\n",
    "E_\\text{out}(g) - E_\\text{in}(g) \\le \\sqrt{{8 \\over N} \\ln {4 m_\\mathcal{H}(2N) \\over \\delta}}\n",
    "$$\n",
    "\n",
    "We need that $E_\\text{out}(g) - E_\\text{in}(g) \\le 0.1$. So this means that\n",
    "\n",
    "$$\n",
    "\\sqrt{{8 \\over N} \\ln {4 m_\\mathcal{H}(2N) \\over \\delta}} = 0.1\n",
    "$$$$\n",
    "\\sqrt{{8 \\over N} \\left (\\ln m_\\mathcal{H}(2N) + \\ln {4 \\over \\delta} \\right )}  = 0.1\n",
    "$$$$\n",
    "\\ln m_\\mathcal{H}(2N) + \\ln {4 \\over \\delta} = 0.01 {N \\over 8}\n",
    "$$$$\n",
    "\\ln 4 - \\ln \\delta = 0.01 {N \\over 8} - \\ln m_\\mathcal{H}(2N)\n",
    "$$$$\n",
    "\\ln \\delta = - 0.01 {N \\over 8} + \\ln m_\\mathcal{H}(2N) + \\ln 4\n",
    "$$$$\n",
    "\\ln \\delta = 6.5646\n",
    "$$$$\n",
    "\\delta = e^{6.5646}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3879dbc",
   "metadata": {},
   "source": [
    "## Exercise 2.6\n",
    "\n",
    "A data set has 600 examples. To properly test the perfomance of the final hypothesis, you set aside a randomly selected subset of 200 examples which are never used in the training phase; these form a test set. You use a learning model with 1000 hypotheses and select the final hypothesis $g$ based on the 400 training examples. We wish to estimate $E_{\\text{out}}(g)$. We have access to two estimates: $E_{\\text{in}}(g)$, the in-sample error on the 400 training examples; and, $E_{\\text{test}}(g)$, the test error on the 200 test examples that were set aside.\n",
    "\n",
    "1. Using a $5\\%$ error tolerance ($\\delta = 0.05$), which estimate has the higher 'error bar'?\n",
    "  \n",
    "2. Is there any reason why you shouldn't reserve even more examples for testing?\n",
    "  \n",
    "### Solution\n",
    "\n",
    "For our $E_\\text{in}$ we only need to see the VC generalization bound.\n",
    "\n",
    "$$\n",
    "E_{\\text{out}}(g) \\le E_\\text{in}(g) + \\sqrt{{8 \\over N} \\ln {4m_\\mathcal{H}(2N) \\over \\delta}}\n",
    "$$\n",
    "\n",
    "with $N = 400$\n",
    "\n",
    "$$\n",
    "\\sqrt{{8 \\over N} ln {4m_\\mathcal{H}(2N) \\over \\delta}} = 0,470486718\n",
    "$$\n",
    "\n",
    "and for $N = 200$ and testing we use the Hoeffding bound\n",
    "\n",
    "$$\n",
    "\\delta \\le 2e^{-2\\epsilon^2N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{ \\delta \\over 2} \\le e^{-2\\epsilon^2N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln { \\delta \\over 2} \\le -2\\epsilon^2N\n",
    "$$\n",
    "\n",
    "$$\n",
    "-{1 \\over 2N} \\ln { \\delta \\over 2} \\le \\epsilon^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sqrt{ -{1 \\over 2N} \\ln { \\delta \\over 2} } \\le \\epsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\epsilon = 0,096032279\n",
    "$$\n",
    "\n",
    "2 The obvious reason we can see from the bounds, the general VC bound been losser when you decrease the number of samples has a more extreme consequence, so you are less sure of the model you selected but more sure of the error when testing. Just caring about the test without caring about the learning process will just give non-good hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e333bc",
   "metadata": {},
   "source": [
    "## Problem 2.1\n",
    "\n",
    "In Equation (2.1), set $\\delta = 0.03$ and let\n",
    "\n",
    "$$\n",
    "\\epsilon(M, N, \\delta)  = \\sqrt{{1 \\over 2N} \\ln {2M \\over \\delta}}.\n",
    "$$\n",
    "\n",
    "1. For $M = 1$, how many examples do we need to make $\\epsilon \\le 0.05$?\n",
    "  \n",
    "2. For $M = 100$, how many examples do we need to make $\\epsilon \\le 0.05$?\n",
    "  \n",
    "3. For $M = 10000$, how many examples do we need to make $\\epsilon \\le 0.05$?\n",
    "  \n",
    "\n",
    "### Solution\n",
    "\n",
    "1\n",
    "\n",
    "$$\n",
    "0.05 \\ge {1 \\over 2N} \\ln {2 \\over 0.03}.\n",
    "$$$$\n",
    "N \\ge {1 \\over 0.1} \\ln {2 \\over 0.03}\n",
    "$$$$\n",
    "N \\ge 41.997\n",
    "$$\n",
    "\n",
    "We need 42 examples or more.\n",
    "\n",
    "2.\n",
    "\n",
    "$$\n",
    "0.05 \\ge {1 \\over 2N} \\ln {2 \\over 0.03}.\n",
    "$$$$\n",
    "N \\ge {1 \\over 0.1} \\ln {200 \\over 0.03}\n",
    "$$$$\n",
    "N \\ge 88,048752639\n",
    "$$\n",
    "\n",
    "We need 89 examples or more\n",
    "\n",
    "3\n",
    "\n",
    "$$\n",
    "0.05 \\ge {1 \\over 2N} \\ln {20000 \\over 0.03}.\n",
    "$$$$\n",
    "N \\ge {1 \\over 0.1} \\ln {20000 \\over 0.03}\n",
    "$$$$\n",
    "N \\ge 134,100454499\n",
    "$$\n",
    "\n",
    "We need 135 examples or more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e78b21",
   "metadata": {},
   "source": [
    "## Problem 2.12\n",
    "\n",
    "For an $\\mathcal{H}$ with $d_{\\text{VC}} = 10$, what sample size do you need (as prescribed by the generalization bound) to have a $95\\%$ confidence that your generalization error is at most $0.05$?\n",
    "\n",
    "We use the equation $(2.13)$\n",
    "\n",
    "$$\n",
    "N \\ge {8 \\over \\epsilon^2} \\ln \\left ( {4((2N)^{d_\\text{VC}} + 1) \\over \\delta} \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61549e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442810\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N_0 = 100\n",
    "N_1 = None\n",
    "while True:\n",
    "    N_1 = 8/(0.05)**2 * math.log((4 * ((2 * N_0)**10 + 1))/0.95)\n",
    "    N_1 = math.ceil(N_1)\n",
    "    if N_1 == N_0:\n",
    "        break\n",
    "    N_0 = N_1\n",
    "print(N_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fd881",
   "metadata": {},
   "source": [
    "Well it seems that the we need a sample size of $442810$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9487e6",
   "metadata": {},
   "source": [
    "## Problem 2.16\n",
    "\n",
    "In this problem, we will consider $\\mathcal{X} = \\mathbb{R}$. That is, $\\mathbf{x} = x$ is a one-dimensional variable. For a hypothesis set\n",
    "\n",
    "$$\n",
    "\\mathcal{H} = \\left \\lbrace h_{\\mathbf{c}} | h_{\\mathbf{c}}(x) = \\text{sign} \\left ( \\sum_{i = 0}^{D} c_ix^i \\right ) \\right \\rbrace\n",
    "$$\n",
    "\n",
    "prove that the VC dimension of $\\mathcal{H}$ is exactly $(D + 1)$ by showing that\n",
    "\n",
    "1. There are $(D + 1)$ points which are shattered by $\\mathcal{H}$.\n",
    "  \n",
    "2. There are no $(D + 2)$ points which are shattered by $\\mathcal{H}$.\n",
    "  \n",
    "\n",
    "### Solution\n",
    "\n",
    "1 To prove that there are $(D+1)$ points shattered by $\\mathcal{H}$ we only need to use the values of $\\mathbf{c}$. We use the values of $+1, -1, 0$. For separating the values.\n",
    "\n",
    "For example $x = 1$ and $x = 2$, we need to separate this to values then we use $c_1 = 1$ and $c_2 = -1$. Also we can used the other value $c_0$ to separate the rest of the entries (outside the examples), so we can separate $(D + 1)$.\n",
    "\n",
    "2 We notice that $\\sum_{i=0}^{D} c_i x^i$ is a polinomial of degree $D$, but also we can imagine the roots as opportunities to change the classification on the $\\mathbb{R}$, so each time we encounter a root the function can go up again (imagine a parabola) or it can go down (a sine wave is the simplest example that comes to mind).\n",
    "\n",
    "So you must start with an option $(+1, -1)$ then you have $D$ possible changes to shattered $(D + 2)$ you would need $D + 1$ possible changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
